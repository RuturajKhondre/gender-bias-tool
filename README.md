# Gender Bias Identification Tool

The Gender Bias Identification Tool is an AI-powered application designed to help users identify and correct gender bias in text, promoting more inclusive language through a combination of rule-based detection and AI-powered analysis.

## Table of Contents
- [Features](#features)
- [AI Usage Documentation](#ai-usage-documentation)
- [Getting Started](#getting-started)
- [Licensing and Contributions](#licensing-and-contributions)

## Features
- **Text Analysis**: Detects gender-biased terms and provides suggestions for alternatives.
- **AI-Powered Suggestions**: Utilizes AI to generate context-aware alternatives and explanations.
- **User-Friendly Interface**: Easy-to-use web interface for text input and analysis.
- **Analysis History**: Save and view previous analyses for reference.

## AI Usage Documentation
### AI Tools Used
- **Hugging Face Transformers**: Used for text generation and classification tasks.
  - **Text Generation**: Utilized for generating alternative text suggestions and explanations.
  - **Text Classification**: Used for sentiment analysis.

### Implementation Details
#### AI Components
- **Text Analysis**: AI models are used to analyze text for gender bias and sentiment.
- **Bias Detection**: AI algorithms help identify biased language patterns and suggest improvements.

#### Human-Created Components
- **Frontend Interface**: Developed using HTML, CSS, and JavaScript.
- **Data Processing**: Logic for processing text input and displaying results was manually coded.
- **Testing & Validation**: Conducted manual testing to ensure accuracy and usability.

### Attribution Statement
This project utilizes the following AI technologies for specific components:
- **Hugging Face Transformers**: Used for generating suggestions and explanations, and for sentiment analysis.

### Development Process
- **Human-Coded Parts**: The frontend interface and data processing logic were entirely human-coded.
- **AI-Assisted Parts**: Text analysis and bias detection were AI-assisted.
- **Documentation**: AI-generated code is clearly commented, and references to AI models' documentation are included.

### Ethical Considerations
- **Potential Biases**: Acknowledge that AI models may have inherent biases due to training data.
- **Mitigation Steps**: Implemented rule-based checks alongside AI to reduce bias.
- **Human Oversight**: All AI-driven decisions are reviewed by human developers to ensure fairness.

## Getting Started
### Prerequisites
- Python 3.7+
- Flask
- Transformers library from Hugging Face

### Installation
1. Clone the repository:
   ```
   git clone https://github.com/RuturajKhondre/gender-bias-tool.git
   cd gender-bias-tool
   ```

2. Install the required packages:
   ```
   pip install -r requirements.txt
   ```

3. Run the application:
   ```
   python app.py
   ```

4. Open your browser and go to `http://localhost:5000` to use the tool.

## Licensing and Contributions
This project is currently in development and is not open for external contributions at this time. All rights to the code and associated documentation are reserved. 

Please note that this project is not licensed for use, modification, or distribution. If you're interested in using or contributing to this project in the future, check back later as this status may change.

![image alt]([image_url](https://github.com/RuturajKhondre/gender-bias-tool/blob/b0f54d12792e8d9b11f201f317678559a2c91d18/page1.png)
![image alt]([image_url](https://github.com/RuturajKhondre/gender-bias-tool/blob/b0f54d12792e8d9b11f201f317678559a2c91d18/page2.png)
![image alt]([image_url](https://github.com/RuturajKhondre/gender-bias-tool/blob/b0f54d12792e8d9b11f201f317678559a2c91d18/page3.png)
![image alt]([image_url](https://github.com/RuturajKhondre/gender-bias-tool/blob/b0f54d12792e8d9b11f201f317678559a2c91d18/page4.png)
![image alt]([image_url](https://github.com/RuturajKhondre/gender-bias-tool/blob/b0f54d12792e8d9b11f201f317678559a2c91d18/page5.png)
![image alt]([image_url](https://github.com/RuturajKhondre/gender-bias-tool/blob/b0f54d12792e8d9b11f201f317678559a2c91d18/page6.png)
![image alt]([image_url](https://github.com/RuturajKhondre/gender-bias-tool/blob/b0f54d12792e8d9b11f201f317678559a2c91d18/page7.png)
![image alt]([image_url](https://github.com/RuturajKhondre/gender-bias-tool/blob/b0f54d12792e8d9b11f201f317678559a2c91d18/page8.png)




